{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textract in /Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages (1.6.5)\n",
      "Requirement already satisfied: argcomplete~=1.10.0 in /Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from textract) (1.10.3)\n",
      "Requirement already satisfied: beautifulsoup4~=4.8.0 in /Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from textract) (4.8.2)\n",
      "Requirement already satisfied: chardet==3.* in /Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from textract) (3.0.4)\n",
      "Requirement already satisfied: docx2txt~=0.8 in /Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from textract) (0.8)\n",
      "Requirement already satisfied: extract-msg<=0.29.* in /Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from textract) (0.28.7)\n",
      "Requirement already satisfied: pdfminer.six==20191110 in /Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from textract) (20191110)\n",
      "Requirement already satisfied: python-pptx~=0.6.18 in /Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from textract) (0.6.21)\n",
      "Requirement already satisfied: six~=1.12.0 in /Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from textract) (1.12.0)\n",
      "Requirement already satisfied: SpeechRecognition~=3.8.1 in /Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from textract) (3.8.1)\n",
      "Requirement already satisfied: xlrd~=1.2.0 in /Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from textract) (1.2.0)\n",
      "Requirement already satisfied: pycryptodome in /Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from pdfminer.six==20191110->textract) (3.18.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from pdfminer.six==20191110->textract) (2.4.0)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from beautifulsoup4~=4.8.0->textract) (2.4)\n",
      "Requirement already satisfied: imapclient==2.1.0 in /Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from extract-msg<=0.29.*->textract) (2.1.0)\n",
      "Requirement already satisfied: olefile>=0.46 in /Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from extract-msg<=0.29.*->textract) (0.46)\n",
      "Requirement already satisfied: tzlocal>=2.1 in /Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from extract-msg<=0.29.*->textract) (4.3)\n",
      "Requirement already satisfied: compressed-rtf>=1.0.6 in /Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from extract-msg<=0.29.*->textract) (1.0.6)\n",
      "Requirement already satisfied: ebcdic>=1.1.1 in /Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from extract-msg<=0.29.*->textract) (1.1.1)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from python-pptx~=0.6.18->textract) (4.9.2)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in /Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from python-pptx~=0.6.18->textract) (9.4.0)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in /Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from python-pptx~=0.6.18->textract) (3.1.2)\n",
      "Requirement already satisfied: pytz-deprecation-shim in /Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from tzlocal>=2.1->extract-msg<=0.29.*->textract) (0.1.0.post0)\n",
      "Requirement already satisfied: tzdata in /Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from pytz-deprecation-shim->tzlocal>=2.1->extract-msg<=0.29.*->textract) (2023.3)\n",
      "\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: tiktoken in /Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages (0.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from tiktoken) (2022.10.31)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
      "\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install textract\n",
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "apiKey = os.getenv('OPENAI_API_KEY')\n",
    "openai.api_key = apiKey\n",
    "print(apiKey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://data.vdsc.com.vn/vi/Com_Document/VNM/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\f            Công ty Cổ phần Sữa Việt Nam và các công ty con        NỘI DUNG         THÔNG TIN VỀ CÔNG TY          BÁO CÁO CỦA BAN ĐIỀU HÀNH          BÁO CÁO TÌNH HÌNH TÀI CHÍNH HỢP NHẤT          BÁO CÁO KẾT QUẢ HOẠT ĐỘNG KINH DOANH HỢP NHẤT          BÁO CÁO LƯU CHUYỂN TIỀN TỆ HỢP NHẤT          THUYẾT MINH BÁO CÁO TÀI CHÍNH HỢP NHẤT     TRANG     2     3          4 - 6     7 - 8     9 - 11     12 - 61    1     \f            Công ty Cổ phần Sữa Việt Nam và các công ty con   Thông tin về Công ty   \n"
     ]
    }
   ],
   "source": [
    "# load the pdf file\n",
    "path = './data/1517456934-51f84d5d6cb5ceae2465a7da470fc533ac4830e4776cc0fd3aa76c0fe7537c8e.pdf'\n",
    "import textract\n",
    "import tiktoken\n",
    "\n",
    "# Extract the raw text from each PDF using textract\n",
    "text = textract.process(path, method='pdfminer').decode('utf-8')\n",
    "clean_text = text.replace(\"  \", \" \").replace(\"\\n\", \"; \").replace(';',' ')\n",
    "print(clean_text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lấy các mẫu thông tin quan trọng từ tài liệu sau đây.\n",
      "Nếu phần thông tin cụ thể không có, hãy xuất ra \"Not specified\".\n",
      "Sử dụng định dạng sau:\n",
      "0. Tài sản dài hạn\n",
      "1. Tỷ suất lợi nhuận\n",
      "2. Tên công ty\n",
      "3. Lợi nhuận\n",
      "\n",
      "Tài liệu: \"\"\"<document>\"\"\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example prompt - \n",
    "document = '<document>'\n",
    "template_prompt=f'''Lấy các mẫu thông tin quan trọng từ tài liệu sau đây.\n",
    "Nếu phần thông tin cụ thể không có, hãy xuất ra \"Not specified\".\n",
    "Sử dụng định dạng sau:\\n0. Tài sản dài hạn\\n1. Tỷ suất lợi nhuận\\n2. Tên công ty\\n3. Lợi nhuận\\n\\nTài liệu: \\\"\\\"\\\"{document}\\\"\\\"\\\"\\n\\n'''\n",
    "\n",
    "print(template_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a text into smaller chunks of size n, preferably ending at the end of a sentence\n",
    "def create_chunks(text, n, tokenizer):\n",
    "    tokens = tokenizer.encode(text)\n",
    "    \"\"\"Yield successive n-sized chunks from text.\"\"\"\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        # Find the nearest end of sentence within a range of 0.5 * n and 1.5 * n tokens\n",
    "        j = min(i + int(1.5 * n), len(tokens))\n",
    "        while j > i + int(0.5 * n):\n",
    "            # Decode the tokens and check for full stop or newline\n",
    "            chunk = tokenizer.decode(tokens[i:j])\n",
    "            if chunk.endswith(\".\") or chunk.endswith(\"\\n\"):\n",
    "                break\n",
    "            j -= 1\n",
    "        # If no end of sentence found, use n tokens as the chunk size\n",
    "        if j == i + int(0.5 * n):\n",
    "            j = min(i + n, len(tokens))\n",
    "        yield tokens[i:j]\n",
    "        i = j\n",
    "\n",
    "def extract_chunk(document, template_prompt):\n",
    "    prompt=template_prompt.replace('<document>', document)\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "        model='text-davinci-003', \n",
    "        prompt=prompt,\n",
    "        temperature=0,\n",
    "        max_tokens=1500,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    return \"1.\" + response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Your account is not active, please check your billing details on our website.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m text_chunks \u001b[39m=\u001b[39m [tokenizer\u001b[39m.\u001b[39mdecode(chunk) \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m chunks]\n\u001b[1;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m text_chunks:\n\u001b[0;32m---> 10\u001b[0m     results\u001b[39m.\u001b[39mappend(extract_chunk(chunk, template_prompt))\n\u001b[1;32m     11\u001b[0m     \u001b[39mprint\u001b[39m(chunk)\n\u001b[1;32m     12\u001b[0m     \u001b[39mprint\u001b[39m(results[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "Cell \u001b[0;32mIn[5], line 24\u001b[0m, in \u001b[0;36mextract_chunk\u001b[0;34m(document, template_prompt)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_chunk\u001b[39m(document, template_prompt):\n\u001b[1;32m     22\u001b[0m     prompt\u001b[39m=\u001b[39mtemplate_prompt\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m<document>\u001b[39m\u001b[39m'\u001b[39m, document)\n\u001b[0;32m---> 24\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     25\u001b[0m         model\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtext-davinci-003\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m     26\u001b[0m         prompt\u001b[39m=\u001b[39;49mprompt,\n\u001b[1;32m     27\u001b[0m         temperature\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     28\u001b[0m         max_tokens\u001b[39m=\u001b[39;49m\u001b[39m1500\u001b[39;49m,\n\u001b[1;32m     29\u001b[0m         top_p\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     30\u001b[0m         frequency_penalty\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     31\u001b[0m         presence_penalty\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m\n\u001b[1;32m     32\u001b[0m     )\n\u001b[1;32m     33\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m1.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m response[\u001b[39m'\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/site-packages/openai/api_requestor.py:619\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    612\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    613\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    614\u001b[0m         )\n\u001b[1;32m    615\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    616\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    618\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 619\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    620\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    623\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    624\u001b[0m         ),\n\u001b[1;32m    625\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    626\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/site-packages/openai/api_requestor.py:679\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    677\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 679\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    680\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    681\u001b[0m     )\n\u001b[1;32m    682\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Your account is not active, please check your billing details on our website."
     ]
    }
   ],
   "source": [
    "# Initialise tokenizer\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "results = []\n",
    "    \n",
    "chunks = create_chunks(clean_text, 1000, tokenizer)\n",
    "text_chunks = [tokenizer.decode(chunk) for chunk in chunks]\n",
    "\n",
    "for chunk in text_chunks:\n",
    "    results.append(extract_chunk(chunk, template_prompt))\n",
    "    print(chunk)\n",
    "    print(results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [r.split('\\n') for r in results]\n",
    "\n",
    "# zip the groups together\n",
    "zipped = list(zip(*groups))\n",
    "zipped = [x for y in zipped for x in y if \"Not specified\" not in x and \"__\" not in x]\n",
    "zipped"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
